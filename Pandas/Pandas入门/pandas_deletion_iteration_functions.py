#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Pandasæ•°æ®åˆ é™¤ã€è¿­ä»£å’Œå‡½æ•°åº”ç”¨å®Œå…¨æ¼”ç¤º
åŸºäºã€ŠPandasé«˜çº§æ“ä½œå®Œå…¨æŒ‡å—ã€‹çš„ç¬¬9ã€10ã€11ç« 

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import pandas as pd
import numpy as np
import time

def main():
    print("=== Pandas æ•°æ®åˆ é™¤ã€è¿­ä»£å’Œå‡½æ•°åº”ç”¨å®Œå…¨æ¼”ç¤º ===\n")

    # åˆ›å»ºå‘˜å·¥æ•°æ®
    df = pd.DataFrame({
        'å§“å': ['å¼ ä¸‰', 'æå››', 'ç‹äº”', 'èµµå…­', 'é’±ä¸ƒ', 'å­™å…«'],
        'å¹´é¾„': [25, 30, 35, 28, 32, 27],
        'éƒ¨é—¨': ['æŠ€æœ¯', 'é”€å”®', 'æŠ€æœ¯', 'å¸‚åœº', 'æŠ€æœ¯', 'é”€å”®'],
        'å·¥èµ„': [8000, 12000, 15000, 10000, 13000, 11000],
        'åŸå¸‚': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'æˆéƒ½'],
        'å…¥èŒæ—¥æœŸ': pd.date_range('2024-01-01', periods=6)
    }, index=['emp1', 'emp2', 'emp3', 'emp4', 'emp5', 'emp6'])

    print("åŸå§‹å‘˜å·¥æ•°æ®:")
    print(df)
    print(f"\næ•°æ®å½¢çŠ¶: {df.shape}")

    # ==================== ç¬¬9ç« : æ•°æ®åˆ é™¤ ====================
    print("\n" + "="*60)
    print("ç¬¬9ç« : æ•°æ®åˆ é™¤ (Dropping Data)")
    print("="*60)

    # 9.1 åˆ é™¤è¡Œå’Œåˆ—
    print("\n9.1 åˆ é™¤è¡Œå’Œåˆ—")
    print("-" * 30)

    # åˆ›å»ºç”¨äºåˆ é™¤æ“ä½œçš„æ•°æ®å‰¯æœ¬
    df_drop = df.copy()

    # åˆ é™¤è¡Œ
    print("1. åˆ é™¤æŒ‡å®šè¡Œ (emp3 å’Œ emp5):")
    df_drop_rows = df_drop.drop(['emp3', 'emp5'])
    print(df_drop_rows[['å§“å', 'å¹´é¾„', 'éƒ¨é—¨']])

    # æŒ‰æ¡ä»¶åˆ é™¤è¡Œ
    print("\n2. åˆ é™¤å¹´é¾„å¤§äº30çš„å‘˜å·¥:")
    df_drop_filtered = df_drop.drop(df_drop[df_drop['å¹´é¾„'] > 30].index)
    print(df_drop_filtered[['å§“å', 'å¹´é¾„', 'éƒ¨é—¨']])

    # åˆ é™¤åˆ—
    print("\n3. åˆ é™¤åŸå¸‚åˆ—:")
    df_drop_cols = df_drop.drop('åŸå¸‚', axis=1)
    # æ˜¾ç¤ºç»“æœ
    print(df_drop_cols.head(3))

    # åˆ é™¤å¤šåˆ—
    print("\n4. åˆ é™¤å¤šåˆ— (å…¥èŒæ—¥æœŸå’ŒåŸå¸‚):")
    df_drop_multi_cols = df_drop.drop(['å…¥èŒæ—¥æœŸ', 'åŸå¸‚'], axis=1)
    print(df_drop_multi_cols.head(3))

    # æŒ‰ä½ç½®åˆ é™¤åˆ—
    print("\n5. æŒ‰ä½ç½®åˆ é™¤åˆ— (åˆ é™¤ç¬¬2ã€4åˆ—):")
    df_drop_by_position = df_drop.drop(df_drop.columns[[1, 3]], axis=1)
    print(df_drop_by_position.head(3))

    # 9.2 é«˜çº§åˆ é™¤æ“ä½œ
    print("\n9.2 é«˜çº§åˆ é™¤æ“ä½œ")
    print("-" * 30)

    # åˆ é™¤é‡å¤è¡Œ
    print("1. åˆ é™¤é‡å¤è¡Œ:")
    # åˆ›å»ºåŒ…å«é‡å¤è¡Œçš„æ•°æ®
    df_with_duplicates = pd.concat([df, df.iloc[2:4]], ignore_index=True)
    print("åŒ…å«é‡å¤è¡Œçš„æ•°æ®:")
    print(df_with_duplicates)

    print("\nåˆ é™¤é‡å¤è¡Œ (ä¿ç•™ç¬¬ä¸€ä¸ª):")
    df_no_duplicates = df_with_duplicates.drop_duplicates()
    print(df_no_duplicates)

    print("\nåˆ é™¤é‡å¤è¡Œ (ä¿ç•™æœ€åä¸€ä¸ª):")
    df_no_duplicates_last = df_with_duplicates.drop_duplicates(keep='last')
    print(df_no_duplicates_last)

    # æŒ‰ç‰¹å®šåˆ—åˆ é™¤é‡å¤
    print("\n2. æŒ‰éƒ¨é—¨åˆ é™¤é‡å¤ (ä¿ç•™ç¬¬ä¸€ä¸ª):")
    df_dept_unique = df.drop_duplicates(subset=['éƒ¨é—¨'], keep='first')
    print(df_dept_unique[['å§“å', 'éƒ¨é—¨']])

    print("\næŒ‰éƒ¨é—¨å’Œå¹´é¾„åˆ é™¤é‡å¤:")
    df_dept_age_unique = df.drop_duplicates(subset=['éƒ¨é—¨', 'å¹´é¾„'], keep='first')
    print(df_dept_age_unique[['å§“å', 'éƒ¨é—¨', 'å¹´é¾„']])

    # åˆ é™¤ç©ºå€¼
    print("\n3. åˆ é™¤ç©ºå€¼:")
    # åˆ›å»ºåŒ…å«ç©ºå€¼çš„æ•°æ®
    df_with_nulls = df.copy()
    df_with_nulls.loc['emp1', 'å¹´é¾„'] = np.nan
    df_with_nulls.loc['emp3', 'å·¥èµ„'] = np.nan
    df_with_nulls.loc['emp5', 'åŸå¸‚'] = np.nan

    print("åŒ…å«ç©ºå€¼çš„æ•°æ®:")
    print(df_with_nulls)

    print("\nåˆ é™¤åŒ…å«ç©ºå€¼çš„è¡Œ:")
    df_no_nulls = df_with_nulls.dropna()
    print(df_no_nulls)

    print("\nåˆ é™¤ç‰¹å®šåˆ—ä¸ºç©ºçš„è¡Œ (å¹´é¾„å’Œå·¥èµ„):")
    df_no_nulls_subset = df_with_nulls.dropna(subset=['å¹´é¾„', 'å·¥èµ„'])
    print(df_no_nulls_subset)

    print("\nåˆ é™¤å…¨ä¸ºç©ºçš„è¡Œ:")
    df_no_all_nulls = df_with_nulls.dropna(how='all')
    print(df_no_all_nulls)

    print("\nåˆ é™¤ç©ºå€¼è¶…è¿‡50%çš„åˆ—:")
    df_few_nulls = df_with_nulls.dropna(axis=1, thresh=len(df_with_nulls) * 0.5)
    print(f"å‰©ä½™åˆ—: {df_few_nulls.columns.tolist()}")

    # 9.3 æ¡ä»¶åˆ é™¤
    print("\n9.3 æ¡ä»¶åˆ é™¤")
    print("-" * 30)

    # åˆ›å»ºæ‰©å±•æ•°æ®
    df_extended = pd.DataFrame({
        'ID': range(1, 11),
        'å§“å': [f'å‘˜å·¥{i}' for i in range(1, 11)],
        'å¹´é¾„': [25, 30, 35, 28, 32, 45, 22, 38, 50, 27],
        'å·¥èµ„': [8000, 12000, 15000, 10000, 13000, 18000, 7000, 14000, 20000, 9000],
        'éƒ¨é—¨': ['æŠ€æœ¯', 'é”€å”®', 'æŠ€æœ¯', 'å¸‚åœº', 'æŠ€æœ¯', 'ç®¡ç†', 'æŠ€æœ¯', 'é”€å”®', 'ç®¡ç†', 'å¸‚åœº'],
        'çŠ¶æ€': ['åœ¨èŒ', 'åœ¨èŒ', 'ç¦»èŒ', 'åœ¨èŒ', 'åœ¨èŒ', 'åœ¨èŒ', 'ç¦»èŒ', 'åœ¨èŒ', 'åœ¨èŒ', 'ç¦»èŒ']
    })

    print("æ‰©å±•æ•°æ®:")
    print(df_extended)

    # åˆ é™¤ç¦»èŒå‘˜å·¥
    print("\n1. åˆ é™¤ç¦»èŒå‘˜å·¥:")
    active_employees = df_extended.drop(df_extended[df_extended['çŠ¶æ€'] == 'ç¦»èŒ'].index)
    print(active_employees)

    # åˆ é™¤å¹´é¾„è¿‡å¤§çš„å‘˜å·¥
    print("\n2. åˆ é™¤å¹´é¾„å¤§äº45å²çš„å‘˜å·¥:")
    age_filtered = df_extended.drop(df_extended[df_extended['å¹´é¾„'] > 45].index)
    print(age_filtered)

    # åˆ é™¤å·¥èµ„è¿‡ä½çš„å‘˜å·¥
    print("\n3. åˆ é™¤å·¥èµ„å°äº8000çš„å‘˜å·¥:")
    salary_filtered = df_extended.drop(df_extended[df_extended['å·¥èµ„'] < 8000].index)
    print(salary_filtered)

    # ç»„åˆæ¡ä»¶åˆ é™¤
    print("\n4. ç»„åˆæ¡ä»¶åˆ é™¤ (å¹´é¾„>40æˆ–å·¥èµ„>15000):")
    complex_filter = (df_extended['å¹´é¾„'] > 40) | (df_extended['å·¥èµ„'] > 15000)
    complex_filtered = df_extended.drop(df_extended[complex_filter].index)
    print(complex_filtered)

    # ä½¿ç”¨ query åˆ é™¤
    print("\n5. ä½¿ç”¨ query ä¿ç•™å¹´é¾„åœ¨25-30ä¹‹é—´çš„å‘˜å·¥:")
    query_filtered = df_extended.query("25 <= å¹´é¾„ <= 30")
    print(query_filtered)

    # ==================== ç¬¬10ç« : æ•°æ®è¿­ä»£ ====================
    print("\n" + "="*60)
    print("ç¬¬10ç« : æ•°æ®è¿­ä»£ (Data Iteration)")
    print("="*60)

    # 10.1 åŸºç¡€è¿­ä»£æ–¹æ³•
    print("\n10.1 åŸºç¡€è¿­ä»£æ–¹æ³•")
    print("-" * 30)

    # iterrows() - é€è¡Œè¿­ä»£ (æ…¢ä½†ä¸æ¨è)
    print("1. ä½¿ç”¨ iterrows() é€è¡Œè¿­ä»£ (å‰3è¡Œ):")
    count = 0
    for index, row in df.iterrows():
        if count < 3:
            print(f"ç´¢å¼•: {index}, å§“å: {row['å§“å']}, å¹´é¾„: {row['å¹´é¾„']}")
            count += 1
        else:
            break

    # itertuples() - æ›´å¿«çš„è¡Œè¿­ä»£
    print("\n2. ä½¿ç”¨ itertuples() é€è¡Œè¿­ä»£ (å‰3è¡Œ):")
    count = 0
    for row in df.itertuples():
        if count < 3:
            print(f"ç´¢å¼•: {row.Index}, å§“å: {row.å§“å}, å¹´é¾„: {row.å¹´é¾„}")
            count += 1
        else:
            break

    # items() - æŒ‰åˆ—è¿­ä»£
    print("\n3. ä½¿ç”¨ items() æŒ‰åˆ—è¿­ä»£:")
    print("\nåˆ—æ•°æ®ç±»å‹:")
    for column_name, column_data in df.items():
        print(f"åˆ—å: {column_name}, æ•°æ®ç±»å‹: {column_data.dtype}")
        if column_name in ['å§“å', 'å¹´é¾„']:
            print(f"  æ•°æ®: {column_data.tolist()}")
            break

    # 10.2 é«˜æ•ˆè¿­ä»£æ–¹æ³•
    print("\n10.2 é«˜æ•ˆè¿­ä»£æ–¹æ³•")
    print("-" * 30)

    # ä½¿ç”¨ apply è¿›è¡Œé«˜æ•ˆæ“ä½œ
    print("1. ä½¿ç”¨ apply è®¡ç®—å·¥èµ„ç­‰çº§:")
    def get_salary_grade(salary):
        if salary < 10000:
            return 'C'
        elif salary < 13000:
            return 'B'
        else:
            return 'A'

    df['å·¥èµ„ç­‰çº§'] = df['å·¥èµ„'].apply(get_salary_grade)
    print(df[['å§“å', 'å·¥èµ„', 'å·¥èµ„ç­‰çº§']])

    # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£è¿­ä»£
    print("\n2. ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£è¿­ä»£:")
    # è®¡ç®—BMIæŒ‡æ•°
    bmi_data = pd.DataFrame({
        'å§“å': ['å¼ ä¸‰', 'æå››', 'ç‹äº”'],
        'ä½“é‡(kg)': [70, 80, 65],
        'èº«é«˜(m)': [1.75, 1.80, 1.70]
    })

    # æ…¢æ–¹æ³• (è¿­ä»£)
    def calculate_bmi_slow(df):
        bmi_list = []
        for _, row in df.iterrows():
            bmi = row['ä½“é‡(kg)'] / (row['èº«é«˜(m)'] ** 2)
            bmi_list.append(round(bmi, 2))
        return bmi_list

    # å¿«æ–¹æ³• (å‘é‡åŒ–)
    def calculate_bmi_fast(df):
        return (df['ä½“é‡(kg)'] / (df['èº«é«˜(m)'] ** 2)).round(2)

    print("BMIæ•°æ®:")
    print(bmi_data)

    bmi_slow = calculate_bmi_slow(bmi_data)
    bmi_fast = calculate_bmi_fast(bmi_data)

    print(f"\nè¿­ä»£æ–¹æ³•: {bmi_slow}")
    print(f"å‘é‡åŒ–æ–¹æ³•: {bmi_fast.tolist()}")
    print(f"ç»“æœç›¸åŒ: {bmi_slow == bmi_fast.tolist()}")

    # æ€§èƒ½å¯¹æ¯”
    print("\n3. æ€§èƒ½å¯¹æ¯”:")
    # åˆ›å»ºå¤§æ•°æ®é›†
    large_df = pd.DataFrame({
        'A': np.random.randn(1000),
        'B': np.random.randn(1000),
        'C': np.random.randn(1000)
    })

    # iterrowsæ–¹æ³•
    start_time = time.time()
    result_slow = []
    for _, row in large_df.iterrows():
        result_slow.append(row['A'] + row['B'] + row['C'])
    slow_time = time.time() - start_time

    # å‘é‡åŒ–æ–¹æ³•
    start_time = time.time()
    result_fast = large_df['A'] + large_df['B'] + large_df['C']
    fast_time = time.time() - start_time

    print(f"iterrowsæ–¹æ³•è€—æ—¶: {slow_time:.4f}ç§’")
    print(f"å‘é‡åŒ–æ–¹æ³•è€—æ—¶: {fast_time:.4f}ç§’")
    print(f"æ€§èƒ½æå‡: {slow_time/fast_time:.2f}å€")

    # 10.3 æ¡ä»¶è¿­ä»£
    print("\n10.3 æ¡ä»¶è¿­ä»£")
    print("-" * 30)

    # åˆ›å»ºæ¡ä»¶æ•°æ®
    condition_df = pd.DataFrame({
        'äº§å“': ['A', 'B', 'C', 'D', 'E'],
        'é”€é‡': [100, 200, 50, 300, 150],
        'ä»·æ ¼': [10, 20, 30, 15, 25]
    })

    print("äº§å“æ•°æ®:")
    print(condition_df)

    # ä½¿ç”¨ loc è¿›è¡Œæ¡ä»¶èµ‹å€¼
    print("\n1. ä½¿ç”¨ loc è¿›è¡Œæ¡ä»¶èµ‹å€¼:")
    condition_df.loc[condition_df['é”€é‡'] > 150, 'çŠ¶æ€'] = 'çƒ­é”€'
    condition_df.loc[condition_df['é”€é‡'] <= 150, 'çŠ¶æ€'] = 'ä¸€èˆ¬'
    print(condition_df)

    # ä½¿ç”¨ where æ–¹æ³•
    print("\n2. ä½¿ç”¨ where æ–¹æ³•:")
    condition_df['è°ƒæ•´ä»·æ ¼'] = condition_df['ä»·æ ¼'].where(
        condition_df['é”€é‡'] > 100,
        condition_df['ä»·æ ¼'] * 0.9
    )
    print(condition_df)

    # ä½¿ç”¨ mask æ–¹æ³• (where çš„åå‘)
    print("\n3. ä½¿ç”¨ mask æ–¹æ³•:")
    condition_df['é«˜ä»·æ ‡è®°'] = condition_df['ä»·æ ¼'].mask(
        condition_df['ä»·æ ¼'] < 20,
        'ä½ä»·'
    ).mask(
        condition_df['ä»·æ ¼'] >= 20,
        'é«˜ä»·'
    )
    print(condition_df)

    # ==================== ç¬¬11ç« : å‡½æ•°åº”ç”¨ ====================
    print("\n" + "="*60)
    print("ç¬¬11ç« : å‡½æ•°åº”ç”¨ (Function Application)")
    print("="*60)

    # 11.1 apply æ–¹æ³•
    print("\n11.1 apply æ–¹æ³•")
    print("-" * 30)

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    func_df = pd.DataFrame({
        'A': [1, 2, 3, 4, 5],
        'B': [10, 20, 30, 40, 50],
        'C': [100, 200, 300, 400, 500]
    })

    print("ç¤ºä¾‹æ•°æ®:")
    print(func_df)

    # å¯¹åˆ—åº”ç”¨å‡½æ•°
    print("\n1. å¯¹æ¯åˆ—åº”ç”¨å‡½æ•°:")
    print("å¯¹æ¯åˆ—æ±‚å’Œ:")
    col_sum = func_df.apply(lambda x: x.sum())
    print(col_sum)

    print("\nå¯¹æ¯åˆ—æ±‚å‡å€¼:")
    col_mean = func_df.apply(lambda x: x.mean())
    print(col_mean)

    print("\nå¯¹æ¯åˆ—æ±‚æœ€å¤§å€¼:")
    col_max = func_df.apply(lambda x: x.max())
    print(col_max)

    # å¯¹è¡Œåº”ç”¨å‡½æ•°
    print("\n2. å¯¹æ¯è¡Œåº”ç”¨å‡½æ•°:")
    print("å¯¹æ¯è¡Œæ±‚å’Œ:")
    row_sum = func_df.apply(lambda x: x.sum(), axis=1)
    print(row_sum)

    print("\nå¯¹æ¯è¡Œæ±‚å‡å€¼:")
    row_mean = func_df.apply(lambda x: x.mean(), axis=1)
    print(row_mean)

    # åº”ç”¨è‡ªå®šä¹‰å‡½æ•°
    print("\n3. åº”ç”¨è‡ªå®šä¹‰å‡½æ•°:")
    def custom_operation(row):
        """è‡ªå®šä¹‰è¡Œæ“ä½œ"""
        return row['A'] * row['B'] + row['C']

    func_df['è®¡ç®—ç»“æœ'] = func_df.apply(custom_operation, axis=1)
    print(func_df)

    # åº”ç”¨å¤šä¸ªå‡½æ•°
    print("\n4. å¯¹åˆ—åº”ç”¨å¤šä¸ªå‡½æ•°:")
    multi_func = func_df[['A', 'B', 'C']].apply(['sum', 'mean', 'std'])
    print(multi_func)

    # 11.2 applymap æ–¹æ³•
    print("\n11.2 applymap æ–¹æ³•")
    print("-" * 30)

    print("1. å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨å¹³æ–¹æ ¹å‡½æ•°:")
    sqrt_data = func_df[['A', 'B', 'C']].map(lambda x: x ** 0.5)
    print(sqrt_data.round(3))

    print("\n2. å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨æ¡ä»¶å‡½æ•°:")
    def conditional_value(x):
        if x < 100:
            return x * 2
        elif x < 300:
            return x * 1.5
        else:
            return x

    conditional_data = func_df[['A', 'B', 'C']].map(conditional_value)
    print(conditional_data)

    print("\n3. å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨å­—ç¬¦ä¸²æ“ä½œ:")
    string_df = pd.DataFrame({
        'first_name': ['John', 'Jane', 'Bob'],
        'last_name': ['Doe', 'Smith', 'Johnson']
    })
    for col in string_df.columns:
        string_df[f'uppercase_{col}'] = string_df[col].map(lambda x: x.upper() if isinstance(x, str) else x)
    print(string_df)

    # 11.3 pipe æ–¹æ³•
    print("\n11.3 pipe æ–¹æ³•")
    print("-" * 30)

    print("1. ä½¿ç”¨ pipe è¿›è¡Œé“¾å¼æ“ä½œ:")

    def add_prefix(df, prefix):
        """æ·»åŠ å‰ç¼€åˆ°åˆ—å"""
        df.columns = [prefix + col for col in df.columns]
        return df

    def multiply_by_factor(df, factor):
        """æ‰€æœ‰æ•°å€¼ä¹˜ä»¥å› å­"""
        return df * factor

    def add_constant(df, constant):
        """æ‰€æœ‰æ•°å€¼åŠ ä¸Šå¸¸æ•°"""
        return df + constant

    # é“¾å¼åº”ç”¨å‡½æ•°
    result = (func_df[['A', 'B', 'C']]
              .pipe(multiply_by_factor, 2)
              .pipe(add_constant, 10)
              .pipe(add_prefix, 'processed_'))

    print("é“¾å¼å¤„ç†ç»“æœ:")
    print(result)

    # å¤æ‚çš„ pipe æ“ä½œ
    print("\n2. å¤æ‚çš„ pipe æ“ä½œ:")
    def data_processing_pipeline(df):
        """æ•°æ®å¤„ç†ç®¡é“"""
        # æ­¥éª¤1: æ ‡å‡†åŒ–
        df_normalized = (df - df.mean()) / df.std()

        # æ­¥éª¤2: è®¡ç®—æ¯è¡Œçš„æ€»å’Œ
        df_normalized['row_sum'] = df_normalized.sum(axis=1)

        # æ­¥éª¤3: æŒ‰æ€»å’Œæ’åº
        df_sorted = df_normalized.sort_values('row_sum', ascending=False)

        return df_sorted

    processed_result = func_df[['A', 'B', 'C']].pipe(data_processing_pipeline)
    print("å¤„ç†ç®¡é“ç»“æœ:")
    print(processed_result.round(3))

    # 11.4 transform æ–¹æ³•
    print("\n11.4 transform æ–¹æ³•")
    print("-" * 30)

    # åˆ›å»ºåˆ†ç»„æ•°æ®
    group_df = pd.DataFrame({
        'éƒ¨é—¨': ['æŠ€æœ¯', 'é”€å”®', 'æŠ€æœ¯', 'å¸‚åœº', 'æŠ€æœ¯', 'é”€å”®', 'å¸‚åœº', 'æŠ€æœ¯'],
        'å§“å': ['å¼ ä¸‰', 'æå››', 'ç‹äº”', 'èµµå…­', 'é’±ä¸ƒ', 'å­™å…«', 'å‘¨ä¹', 'å´å'],
        'å·¥èµ„': [8000, 12000, 15000, 10000, 13000, 11000, 9000, 14000]
    })

    print("åˆ†ç»„æ•°æ®:")
    print(group_df)

    # transform ä¸ groupby ç»“åˆ
    print("\n1. ä½¿ç”¨ transform è®¡ç®—éƒ¨é—¨å¹³å‡å·¥èµ„:")
    group_df['éƒ¨é—¨å¹³å‡å·¥èµ„'] = group_df.groupby('éƒ¨é—¨')['å·¥èµ„'].transform('mean')
    print(group_df[['å§“å', 'éƒ¨é—¨', 'å·¥èµ„', 'éƒ¨é—¨å¹³å‡å·¥èµ„']])

    print("\n2. è®¡ç®—å·¥èµ„ä¸éƒ¨é—¨å¹³å‡çš„å·®å¼‚:")
    group_df['å·¥èµ„å·®å¼‚'] = group_df['å·¥èµ„'] - group_df['éƒ¨é—¨å¹³å‡å·¥èµ„']
    print(group_df[['å§“å', 'éƒ¨é—¨', 'å·¥èµ„', 'éƒ¨é—¨å¹³å‡å·¥èµ„', 'å·¥èµ„å·®å¼‚']])

    print("\n3. æ ‡å‡†åŒ–æ¯ä¸ªéƒ¨é—¨å†…çš„å·¥èµ„:")
    group_df['æ ‡å‡†åŒ–å·¥èµ„'] = group_df.groupby('éƒ¨é—¨')['å·¥èµ„'].transform(
        lambda x: (x - x.mean()) / x.std()
    )
    print(group_df[['å§“å', 'éƒ¨é—¨', 'å·¥èµ„', 'æ ‡å‡†åŒ–å·¥èµ„']].round(3))

    print("\n4. è®¡ç®—éƒ¨é—¨å†…å·¥èµ„æ’å:")
    group_df['éƒ¨é—¨å†…æ’å'] = group_df.groupby('éƒ¨é—¨')['å·¥èµ„'].transform('rank', ascending=False)
    print(group_df[['å§“å', 'éƒ¨é—¨', 'å·¥èµ„', 'éƒ¨é—¨å†…æ’å']])

    # ==================== å®ç”¨æŠ€å·§å’Œæœ€ä½³å®è·µ ====================
    print("\n" + "="*60)
    print("å®ç”¨æŠ€å·§å’Œæœ€ä½³å®è·µ")
    print("="*60)

    # æŠ€å·§1: é«˜æ•ˆçš„æ•°æ®æ¸…æ´—å‡½æ•°
    print("\n1. é«˜æ•ˆçš„æ•°æ®æ¸…æ´—å‡½æ•°:")
    def clean_data(df):
        """æ•°æ®æ¸…æ´—ç®¡é“"""
        # åˆ é™¤é‡å¤è¡Œ
        df_clean = df.drop_duplicates()

        # å¤„ç†ç¼ºå¤±å€¼
        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
        df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].median())

        # æ ‡å‡†åŒ–åˆ—å
        df_clean.columns = df_clean.columns.str.lower().str.replace(' ', '_')

        return df_clean

    # åˆ›å»ºå¸¦é—®é¢˜çš„æ•°æ®è¿›è¡Œæ¼”ç¤º
    dirty_data = pd.DataFrame({
        'Name': ['Alice', 'Bob', 'Alice', None],
        'Age': [25, 30, 25, 35],
        'Salary': [50000, None, 50000, 60000]
    })

    print("åŸå§‹æ•°æ®:")
    print(dirty_data)

    cleaned_data = clean_data(dirty_data)
    print("\næ¸…æ´—åæ•°æ®:")
    print(cleaned_data)

    # æŠ€å·§2: æ€§èƒ½ä¼˜åŒ–çš„å‡½æ•°åº”ç”¨
    print("\n2. æ€§èƒ½ä¼˜åŒ–çš„å‡½æ•°åº”ç”¨:")

    # åˆ›å»ºå¤§æ•°æ®é›†
    performance_df = pd.DataFrame({
        'value1': np.random.randn(10000),
        'value2': np.random.randn(10000),
        'category': np.random.choice(['A', 'B', 'C'], 10000)
    })

    # æ…¢æ–¹æ³• - apply
    start_time = time.time()
    slow_result = performance_df.apply(lambda row: row['value1'] * row['value2'], axis=1)
    slow_time = time.time() - start_time

    # å¿«æ–¹æ³• - å‘é‡åŒ–
    start_time = time.time()
    fast_result = performance_df['value1'] * performance_df['value2']
    fast_time = time.time() - start_time

    print(f"applyæ–¹æ³•è€—æ—¶: {slow_time:.4f}ç§’")
    print(f"å‘é‡åŒ–æ–¹æ³•è€—æ—¶: {fast_time:.4f}ç§’")
    print(f"æ€§èƒ½æå‡: {slow_time/fast_time:.2f}å€")

    # æŠ€å·§3: è‡ªå®šä¹‰èšåˆå‡½æ•°
    print("\n3. è‡ªå®šä¹‰èšåˆå‡½æ•°:")

    def custom_aggregation(group):
        """è‡ªå®šä¹‰èšåˆå‡½æ•°"""
        return pd.Series({
            'count': len(group),
            'mean': group['value1'].mean(),
            'std': group['value1'].std(),
            'range': group['value1'].max() - group['value1'].min()
        })

    # å¯¹æ€§èƒ½æ•°æ®æŒ‰ç±»åˆ«åˆ†ç»„
    agg_result = performance_df.groupby('category').apply(custom_aggregation)
    print("è‡ªå®šä¹‰èšåˆç»“æœ:")
    print(agg_result.round(3))

    # æŠ€å·§4: é“¾å¼æ“ä½œçš„æœ€ä½³å®è·µ
    print("\n4. é“¾å¼æ“ä½œçš„æœ€ä½³å®è·µ:")

    chained_result = (performance_df
                     .query('value1 > 0')
                     .assign(product=lambda x: x['value1'] * x['value2'])
                     .groupby('category')
                     .agg({
                         'value1': ['mean', 'std'],
                         'product': 'sum'
                     })
                     .round(3))

    print("é“¾å¼æ“ä½œç»“æœ:")
    print(chained_result)

    print("\n" + "="*60)
    print("æ•°æ®åˆ é™¤ã€è¿­ä»£å’Œå‡½æ•°åº”ç”¨æ¼”ç¤ºå®Œæˆ!")
    print("="*60)

    # æ€»ç»“
    print("\nã€æ“ä½œæ€»ç»“ã€‘")
    print("ğŸ—‘ï¸ æ•°æ®åˆ é™¤:")
    print("  âœ“ åŸºç¡€åˆ é™¤: drop() - è¡Œåˆ—åˆ é™¤/æ¡ä»¶åˆ é™¤/æŒ‰ä½ç½®åˆ é™¤")
    print("  âœ“ é«˜çº§åˆ é™¤: drop_duplicates() - é‡å¤å€¼å¤„ç†")
    print("  âœ“ ç©ºå€¼å¤„ç†: dropna() - å¤šç§ç©ºå€¼åˆ é™¤ç­–ç•¥")
    print("  âœ“ æ¡ä»¶åˆ é™¤: query() + ç´¢å¼•æ“ä½œ")

    print("\nğŸ”„ æ•°æ®è¿­ä»£:")
    print("  âœ“ åŸºç¡€è¿­ä»£: iterrows(), itertuples(), items()")
    print("  âœ“ é«˜æ•ˆæ–¹æ³•: apply() - æ›¿ä»£æ˜¾å¼å¾ªç¯")
    print("  âœ“ å‘é‡åŒ–: ä¼˜å…ˆä½¿ç”¨å‘é‡åŒ–æ“ä½œ")
    print("  âœ“ æ¡ä»¶è¿­ä»£: where(), mask() - æ¡ä»¶å¼æ“ä½œ")

    print("\nâš™ï¸ å‡½æ•°åº”ç”¨:")
    print("  âœ“ apply: æŒ‰è¡Œ/åˆ—åº”ç”¨å‡½æ•°")
    print("  âœ“ applymap: æŒ‰å…ƒç´ åº”ç”¨å‡½æ•°")
    print("  âœ“ pipe: é“¾å¼å‡½æ•°åº”ç”¨")
    print("  âœ“ transform: åˆ†ç»„å˜æ¢æ“ä½œ")

    print("\nâš¡ æ€§èƒ½ä¼˜åŒ–:")
    print("  âœ“ ä¼˜å…ˆä½¿ç”¨å‘é‡åŒ–æ“ä½œè€Œéå¾ªç¯")
    print("  âœ“ åˆç†é€‰æ‹©è¿­ä»£æ–¹æ³•")
    print("  âœ“ ä½¿ç”¨é“¾å¼æ“ä½œæé«˜å¯è¯»æ€§")
    print("  âœ“ è‡ªå®šä¹‰èšåˆå‡½æ•°æé«˜æ•ˆç‡")

    print(f"\nåŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print("æ‰€æœ‰åˆ é™¤ã€è¿­ä»£å’Œå‡½æ•°åº”ç”¨æ¼”ç¤ºå‡æˆåŠŸå®Œæˆ! ğŸš€")

if __name__ == "__main__":
    main()